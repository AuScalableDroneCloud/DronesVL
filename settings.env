####################################################################################################
# OpenDroneMap on k8s for ASDC DronesVL
# Owen Kaluza, Monash University, August 2020
#
# Settings and setup script - use "source settings.env" to apply
#
# - This script also sets up access to openstack and the kubernetes cluster - required to use kubectl
# - Needs openstack nectar credentials (set with RC_FILE or source before running)
####################################################################################################
set -a #Exports all variables

#Availability zone
ZONE=monash-02
#Default kubernetes versions (for production, can be different in dev)
#Roll out 1.23.8 in production - NEW LABELS MINUS CONTAINERD all working fine
KUBE_TAG=v1.23.8
LABELS=container_infra_prefix=registry.rc.nectar.org.au/nectarmagnum/,kube_tag=$KUBE_TAG,flannel_tag=v0.18.1,master_lb_floating_ip_enabled=true,docker_volume_type=standard,availability_zone=${ZONE},cinder_csi_enabled=true,ingress_controller=octavia,cloud_provider_tag=v1.23.4,cinder_csi_plugin_tag=v1.23.4,k8s_keystone_auth_tag=v1.23.4,magnum_auto_healer_tag=v1.23.4,octavia_ingress_controller_tag=v1.23.4,autoscaler_tag=v1.23.0,coredns_tag=1.9.3,csi_snapshotter_tag=v4.2.1,csi_attacher_tag=v3.3.0,csi_resizer_tag=v1.3.0,csi_provisioner_tag=v3.0.0,csi_node_driver_registrar_tag=v2.4.0

#Image to use for nodes
#See: https://wiki.openstack.org/wiki/Magnum#Compatibility_Matrix and kube_tag label
IMAGE=fedora-coreos-35
#Must match version in current build at https://github.com/AuScalableDroneCloud/nvidia-driver-build-fedora
NVIDIA_DRIVER="515.86.01"

####################################################################################################
# Must set ASDC_ENV=PRODUCTION to use production settings
echo "****************************************************************************************"
if [ "${ASDC_ENV}" = "PRODUCTION" ]; then
  echo " ** USING PRODUCTION ENVIRONMENT SETTINGS **"
  echo "****************************************************************************************"
  #Use our config file from openstack magnum for kubectl
  export KUBECONFIG=$(pwd)/secrets/kubeconfig

  RUNTIME=docker #Still using docker in production

  #Hostname where app will run
  WEBAPP_HOST=asdc.cloud.edu.au
  WEBAPP_IP=118.138.248.159

  #Volume IDs - store these now, for asdc_update.sh
  export DB_VOLUME_ID=9ee0ead5-903c-466b-a51b-fe87986df30b

  #Set cluster name and prefix for creating nodegroup clusters
  CLUSTER=asdc-k8s

  #Number of nodes in cluster
  MASTER_NODES=3
  APP_NODES=2
  NODES_P4=0
  NODES_A40=4   #2 servers, 2 nodes per server, 2 gpu per node
  NODES_A100=2  #1 server, 2 nodes per server, 2 gpu per nodew
  NODE_METASHAPE=0

  #Volume sizes for persistent storage in GB
  DOCKER_VOL_SIZE=50
  CLUSTER_DOCKER_VOL_SIZE=100
  # - Volume assigned to each NodeODM/ClusterODM processing nodes
  NODE_VOLUME_SIZE=200 #Unused when using local scratch mounts
  # - PostresSQL Database for the webapp
  DB_VOLUME_SIZE=45
  # - Working volume for the webapp
  WEBAPP_VOLUME_SIZE=50
  # - Working volume for tusd uploads
  TUSD_VOLUME_SIZE=300
  UPPY_VOLUME_SIZE=50
  TUSD_BUCKET=asdc-uploads

  #Curated pipelines list
  PIPELINES_URL="https://raw.githubusercontent.com/AuScalableDroneCloud/pipelines-jupyter/main/pipelines.yaml"
  PIPELINE_REPO="https://github.com/auscalabledronecloud/pipelines-jupyter"
else
  echo " ** USING DEVELOPMENT ENVIRONMENT SETTINGS **"
  echo "****************************************************************************************"
  #Use our config file from openstack magnum for kubectl
  export KUBECONFIG=$(pwd)/secrets/kubeconfig-dev

  #RUNTIME=containerd
  RUNTIME=docker #Reverting to docker until issues with gpu-operator fixed

  #Hostname where app will run
  WEBAPP_HOST=dev.asdc.cloud.edu.au
  WEBAPP_IP=118.138.249.245

  #Volume IDs - store these now, for asdc_update.sh
  export DB_VOLUME_ID=3380dd05-d5eb-4042-9b17-128d09aef132

  #Set cluster name and prefix for creating nodegroup clusters
  CLUSTER=asdc-k8s-dev
  #Number of nodes in cluster
  MASTER_NODES=1
  APP_NODES=1
  NODES_P4=2
  NODES_A40=0
  NODES_A100=0
  NODE_METASHAPE=0

  #Volume sizes for persistent storage in GB
  DOCKER_VOL_SIZE=50
  CLUSTER_DOCKER_VOL_SIZE=50
  # - Volume assigned to each NodeODM/ClusterODM processing nodes
  NODE_VOLUME_SIZE=100 #Larger ephemeral volumes as P4 nodes have no local scratch mounts
  # - PostresSQL Database for the webapp
  DB_VOLUME_SIZE=10
  # - Working volume for the webapp
  WEBAPP_VOLUME_SIZE=50
  # - Working volume for tusd uploads
  TUSD_VOLUME_SIZE=100
  UPPY_VOLUME_SIZE=50
  TUSD_BUCKET=asdc-uploads

  #Curated pipelines list
  PIPELINES_URL="https://raw.githubusercontent.com/AuScalableDroneCloud/pipelines-jupyter/development/pipelines.yaml"
  PIPELINE_REPO="https://github.com/auscalabledronecloud/pipelines-jupyter"

  RUNTIME=docker
fi
####################################################################################################
#Switch to containerd
if [ "${RUNTIME}" = "containerd" ]; then
  LABELS=${LABELS},container_runtime=containerd,containerd_version=1.6.6,containerd_tarball_sha256=a64568c8ce792dd73859ce5f336d5485fcbceab15dc3e06d5d1bc1c3353fa20f
fi

#Settings that apply to both dev and produciton

#Openstack rc file
RC_FILE=secrets/Monash-Drone-openrc.sh

#Set cluster template name to create
TEMPLATE=${CLUSTER}-template
NODEGROUP_BASE=gpu

#This is the default keypair, needs to be the name of an existing keypair in openstack
KEYPAIR=ASDC_ODM
#Private key
KEYFILE=secrets/${KEYPAIR}.pem
#External network
NETWORK=monash
#Flavour for the master node used for kubernetes
MASTER_FLAVOUR=m3.small
#Flavours for the minions - this is where the actual pods are deployed
APP_FLAVOUR=m3.xlarge
CLUSTER_P4_FLAVOUR=mon.c22r60.gpu-p4   #60G RAM
CLUSTER_A40_FLAVOUR=mon.c52r460.2gpu-A40.numa #2xGPU,460GB,52,1.5TB
CLUSTER_A100_FLAVOUR=mon.c52r460.2gpu-A100.numa #2xGPU,460GB,52,1.5TB

#Pod replicas # per vm node * node count
#NODEODM_CPU_REPLICAS=$(( 1*APP_NODES )) #When using only app nodes
NODEODM_CPU_REPLICAS=$(( NODES_P4 + NODES_A40 + NODES_A100)) #1 cpu replica per compute node
NODEODM_P4_REPLICAS=$(( 1*NODES_P4 ))
NODEODM_A40_REPLICAS=$(( 2*NODES_A40 ))
NODEODM_A100_REPLICAS=$(( 2*NODES_A100 )) #1 replica per GPU

#Secrets
#Secret env file - contains keys for auth0 etc
#If secrets file doesn't exist, attempt to copy from keybase
SECRET_FILE=secrets/secret.env
if [ ! -f $SECRET_FILE ];
then
  #If keybase command available, try and get the key
  if command -v keybase &> /dev/null; then
    echo "Attempting to get secret files from keybase team folder..."
    keybase fs cp /keybase/team/asdc.admin/secret.env ./secrets/
    keybase fs cp /keybase/team/asdc.admin/kubeconfig ./secrets/
    keybase fs cp /keybase/team/asdc.admin/kubeconfig-dev ./secrets/
  fi

  if [ ! -f "secrets/secret.env" ]; then
    echo "Please download the secret files and store here in: ./secrets/"
    echo "Install keybase and join the asdc.admin team to get keys automatically"
    exit
  fi
fi

if [ -f $SECRET_FILE ];
then
  echo "Using $SECRET_FILE."
  source $SECRET_FILE
fi
#Auth0 key/secret
if [ -z ${WO_AUTH0_KEY+x} ] || [ -z ${WO_AUTH0_SECRET+x} ] || [ -z ${WO_AUTH0_DOMAIN+x} ];
then
  echo "Secret env file $SECRET_FILE does not exist or is missing values."
  echo "Please set key/secrets to use, see: secrets/secret.env.template"
fi

#Generate keys for JWT or use existing
JWT_KEY=secrets/jwt-key
if [ ! -f $JWT_KEY ];
then
    openssl genrsa -out $JWT_KEY 4096
    chmod 600 $JWT_KEY
    openssl rsa -in $JWT_KEY -pubout > $JWT_KEY.pub
    os.environ['JWT_PRIVATE_KEY_PATH'] = 'jwt-key'
    os.environ['JWT_PUBLIC_KEY_PATH'] = 'jwt-key.pub'
fi

####################################################################################################

#Ensure ID set for openstack
if [ -z ${OS_PROJECT_ID+x} ];
then
  echo "OS_PROJECT_ID is unset";
  if [ -f $RC_FILE ]; then
    echo "Using $RC_FILE."
    source $RC_FILE
  else
    echo "Openstack rc file $RC_FILE does not exist."
    echo "Please source your openstack credentials to enable access"
    echo "(continuing but only kubectl admin will be enabled)"
  fi
else
  echo "OS_PROJECT_ID is set to '$OS_PROJECT_ID'";
fi

# Generate the secret tokens for jupyterhub
if [ -z ${JHUB_SECRET_TOKEN+x} ];
then
  echo "Generating new JupyterHub secret token"
  JHUB_SECRET_TOKEN=$(openssl rand -hex 32)
  JHUB_CRYPT_KEEPER_KEY1=$(openssl rand -hex 32)
fi

# Generate the secret tokens for WebODM field encryption
if [ -z ${WO_ENCRYPTION_KEY+x} ];
then
  echo "Generating new WebODM secret token"
  WO_ENCRYPTION_KEY=$(openssl rand -hex 16)
fi

####################################################################################################

#If secrets/kubeconfig exists, use it for kubectl
if [ -s "secrets/kubeconfig" ] && grep "${CLUSTER}" secrets/kubeconfig;
then
  export KUBECONFIG=$(pwd)/secrets/kubeconfig
  echo "Set KUBECONFIG='$KUBECONFIG'";
fi

#Check for dependencies
#Ensure flux version doesn't bounce around
FLUX_VERSION=2.0.0-rc.4
if ! command -v kubectl &> /dev/null
then
  #Add cwd to path so local kubectl can be run without ./
  PATH=$PATH:$(pwd)
  if ! command -v kubectl &> /dev/null
  then
    echo "kubectl could not be found! running ./install.sh to install dependencies"
    ./install.sh
  fi
fi

if ! command -v helm &> /dev/null
then
  echo "helm could not be found! running ./install.sh to install dependencies"
  ./install.sh
fi

if ! command -v openstack &> /dev/null
then
  echo "openstack could not be found! running ./install.sh to install dependencies"
  ./install.sh
fi

if ! command -v flux &> /dev/null
then
  echo "flux could not be found! running ./install.sh to install dependencies"
  ./install.sh
fi
FLUXVER=$(flux --version | cut -d " " -f 3)
if [ "${FLUX_VERSION}" != "${FLUXVER}" ];
then
  echo "FLUX VERSION MISMATCH: ${FLUXVER} != ${FLUX_VERSION}"
  sleep 2
  return 1
fi

#Utility functions used in other scripts
function subst_template()
{
  #Use envsubst to apply variables to template .yaml files
  #$1 = filename.yaml

  #Runs envsubst but skips vars not defined in env https://unix.stackexchange.com/a/492778/17168
  cat templates/$1 | envsubst "$(env | cut -d= -f1 | sed -e 's/^/$/')" > yaml/$1
  echo "Applied env to template: templates/$1 => yaml/$1"
}

function apply_template()
{
  #Substitute env vars
  subst_template $1
  #Apply to cluster
  kubectl apply -f yaml/$1
}

STATUS=''
function get_status()
{
  #Get the status of the running cluster
  STATUS=$(openstack coe cluster show $CLUSTER -f value -c status)
}

function cluster_check()
{
  #if [ "$STATUS" == $1 ]; then
  #Checks for desired status as sub-string,
  #eg: UPDATE_COMPLETE/CREATE_COMPLETE will match COMPLETE
  if [[ "$STATUS" == *"$1"* ]]; then
    return 0
  fi
  return 1
}

function cluster_launched()
{
  if cluster_check "COMPLETE" ; then
    return 0
  fi
  if cluster_check "CREATE_IN_PROGRESS"; then
    return 0
  fi
  return 1
}

function wait_for_pod()
{
  #Loop until pod is running
  #$1 = pod name
  until kubectl get pods --field-selector status.phase=Running | grep $1
  do
    echo "Waiting for pod to enter status=Running : $1"
    sleep 2
  done
  echo "Pod is running : $1"
}



